trainer:
  log_every_n_steps: 10
  max_epochs: 200
model:
  init_args:
    optimizer:
      class_path: torch.optim.Adam
      init_args:
        lr: 0.0005
    scheduler:
      class_path: torch.optim.lr_scheduler.LinearLR
      init_args:
        start_factor: 1.
        end_factor: 0.1
        total_iters: 10
